# Agentic Testing System (Mockup)

è¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿ Federico De Ponte æè¿°çš„â€œå¤šæ™ºèƒ½ä½“å¹¶è¡Œä»£ç ç”Ÿæˆ+æµ‹è¯•â€ç³»ç»Ÿçš„ç®€åŒ–ç¤ºä¾‹ã€‚

åŠŸèƒ½æ¼”ç¤ºï¼š
1. orchestrator åˆ†å‘ä»»åŠ¡
2. code_agent ç”Ÿæˆç¤ºä¾‹ä»£ç ï¼ˆè¿™é‡Œç”¨çš„æ˜¯å‡ä»£ç ï¼‰
3. test_agent ç”Ÿæˆ pytest æµ‹è¯•
4. run_agent è¿è¡Œæµ‹è¯•å¹¶è¿”å›ç»“æœ
5. repair_agent åœ¨å¤±è´¥æ—¶å°è¯•ä¿®å¤

è¿è¡Œæ–¹å¼ï¼š
```bash
cd agentic-testing-system
python orchestrator/orchestrator.py

python -m orchestrator.orchestrator
```

æ³¨æ„ï¼š
- è¿™æ˜¯ç¤ºæ„é¡¹ç›®ï¼Œä¸ä¼šçœŸçš„è¿æ¥ Claude / Cursorã€‚
- ä½ å¯ä»¥åœ¨ agents/* é‡Œæ›¿æ¢æˆä½ è‡ªå·±çš„ API è°ƒç”¨é€»è¾‘ã€‚


Short Version

He built an AI system that works like a 24/7 coding factory.
It uses many AI coders (Claude Code) running together, each doing a different job â€” one writes code, one tests it, one fixes bugs.

A central program (called the orchestrator) manages them all â€” it decides who does what, checks the results, and restarts tasks when something fails.

Everything runs on 16 NVIDIA GPUs in the cloud, so it never sleeps.

The whole thing is like an AI DevOps pipeline â€” code â†’ test â†’ fix â†’ repeat â€” until everything works perfectly.

In short: itâ€™s an AI-native workflow system that lets machines code and debug themselves, with humans only watching the progress.

ä»–å»ºç«‹äº†ä¸€ä¸ªæ™ºèƒ½ä½“ç¼–æ’ç³»ç»Ÿï¼ˆAgentic Orchestration Systemï¼‰ï¼Œ
ç”¨äºåœ¨ GPU é›†ç¾¤ä¸Šå¹¶è¡Œåè°ƒå¤šä¸ª AI ç¼–ç æ™ºèƒ½ä½“ï¼ˆClaude Code å®ä¾‹ï¼‰çš„è¿è¡Œã€‚
è¯¥ç³»ç»Ÿèåˆäº† MLOpsï¼ˆæœºå™¨å­¦ä¹ è¿ç»´ï¼‰ã€AI åŸºç¡€è®¾æ–½å·¥ç¨‹ï¼ˆAI Infrastructure Engineeringï¼‰ å’Œ å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ˆMASï¼‰ çš„è®¾è®¡ç†å¿µã€‚

ç³»ç»Ÿç»“æ„åŒ…æ‹¬äº”å±‚ï¼š

åŸºç¡€è®¾æ–½å±‚ï¼ˆInfrastructure Layerï¼‰ï¼š
â€ƒä½¿ç”¨ 16 å— NVIDIA L4 GPU å’Œ Google äº‘ VMï¼Œæä¾›è®¡ç®—ç¯å¢ƒã€‚

ç¼–æ’å±‚ï¼ˆOrchestration Layerï¼‰ï¼š
â€ƒæ ¸å¿ƒæ§åˆ¶ç³»ç»Ÿï¼Œç”¨äºè°ƒåº¦ä»»åŠ¡ã€ç›‘æ§ Agent çŠ¶æ€ã€è§¦å‘è‡ªåŠ¨ä¿®å¤å¾ªç¯ã€‚

æ™ºèƒ½ä½“å±‚ï¼ˆAgent Layerï¼‰ï¼š
â€ƒç”±å¤šä¸ª Claude Code å®ä¾‹ç»„æˆï¼Œæ¯ä¸ªæ‰§è¡Œä¸åŒä»»åŠ¡ï¼ˆå†™ä»£ç ã€å†™æµ‹è¯•ã€è·‘æµ‹è¯•ã€ä¿®å¤ï¼‰ã€‚

è‡ªåŠ¨åŒ–å¾ªç¯å±‚ï¼ˆAutomation & Feedback Loopï¼‰ï¼š
â€ƒå½¢æˆ Code â†’ Test â†’ Repair â†’ Re-test çš„é—­ç¯ï¼Œæ— éœ€äººå·¥å¹²é¢„ã€‚

ç›‘æ§å±‚ï¼ˆObservation & Reporting Layerï¼‰ï¼š
â€ƒé€šè¿‡ Slack ç­‰å¹³å°æ±‡æŠ¥ç»“æœï¼Œå®ç°äººæœºååŒç›‘ç£ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œè¿™æ˜¯ä¸€ç§ AI åŸç”Ÿçš„è‡ªåŠ¨å¼€å‘ç®¡çº¿ï¼Œ
èƒ½è®©æœºå™¨è‡ªè¡Œç¼–å†™ã€æµ‹è¯•ã€ä¿®å¤ä»£ç ï¼Œäººç±»åªéœ€ç›‘æ§è¿›åº¦ã€‚

Er hat ein Agentic Orchestration System entwickelt,
das mehrere AI-Coding-Agents (Claude Code Instanzen) parallel auf einem GPU-Cluster koordiniert.
Das System kombiniert Konzepte aus MLOps, AI-Infrastruktur-Engineering und Multi-Agent-System (MAS)-Design.

Das System besteht aus fÃ¼nf Ebenen:

Infrastrukturebene:
â€ƒ16 Ã— NVIDIA L4-GPUs und Google-Cloud-VMs bilden die Rechenbasis.

Orchestrierungsebene:
â€ƒDer zentrale Workflow-Controller steuert Aufgaben, Ã¼berwacht den Status der Agents und startet bei Fehlern automatische Reparaturzyklen.

Agent-Ebene:
â€ƒMehrere Claude Code Instanzen mit spezifischen Rollen â€“ Code schreiben, Tests erstellen, ausfÃ¼hren und Fehler beheben.

Automatisierungs- & Feedback-Schleife:
â€ƒEin geschlossener Loop (Code â†’ Test â†’ Repair â†’ Re-Test) ohne menschliche Eingriffe.

Ãœberwachungs- & Reporting-Ebene:
â€ƒSlack-Integration und zentrale Logs ermÃ¶glichen menschliche Kontrolle und Analyse.

Kurz gesagt: Es ist eine AI-native Entwicklungs-Pipeline,
die Code autonom schreibt, testet und verbessert, wÃ¤hrend Menschen nur den Prozess beobachten.

ç¬¬ä¸€éƒ¨åˆ†ï¼šå¯æ“ä½œæ€§ä¸å¯å¤åˆ¶æ€§ï¼ˆå®ç”¨è§’åº¦åˆ†æï¼‰

æˆ‘ä»¬æ¥çœ‹ï¼šFederico De Ponte çš„ç³»ç»Ÿä¹‹æ‰€ä»¥èƒ½åšåˆ° > 14 Claude Code + 16 L4 GPU + 24/7 è¿è¡Œï¼Œé çš„æ˜¯ä¼ä¸šçº§èµ„æºã€‚
ä½†â€”â€”è¿™å¹¶ä¸æ„å‘³ç€ä½ åšä¸äº†â€œå°å‹å¯å¤åˆ¶ç‰ˆâ€ã€‚

ä¸‹é¢æˆ‘ç»™ä½ ä¸‰å±‚ç°å®å¯¹æ¯”ğŸ‘‡

â‘  ä¼ä¸šçº§ç‰ˆæœ¬ï¼ˆä»–åšçš„ï¼‰

ç®—åŠ›æ¥æºï¼šGoogle Cloud + 16 Ã— NVIDIA L4 GPU

VM æ¶æ„ï¼šåˆ†å¸ƒå¼ Kubernetes é›†ç¾¤ï¼Œè‡ªåŠ¨ä¼¸ç¼©ã€è´Ÿè½½å‡è¡¡

Agent è§„æ¨¡ï¼šåŒæ—¶å¹¶è¡Œ 14â€“20 ä¸ª Claude Code å®ä¾‹

ç‰¹ç‚¹ï¼šè‡ªåŠ¨åŒ–ã€é«˜ååã€æŒç»­è¿è¡Œ 24/7

æˆæœ¬ï¼šçº¦ æ¯æœˆ $15 000 â€“ $30 000ï¼ˆå« GPU ç§Ÿç”¨ã€API token æ¶ˆè€—ï¼‰

å¯æ“ä½œæ€§ï¼šâ­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ï¼ˆä½†åªå¯¹æœ‰å…¬å¸èµ„æºçš„äººï¼‰

â‘¡ é«˜çº§ä¸ªäººç‰ˆï¼ˆå¯å®ç°ï¼‰

ç®—åŠ›æ¥æºï¼šäº‘ç«¯ GPU å¹³å°ï¼ˆå¦‚ RunPodã€Paperspaceã€Lambda Labsã€Google Cloud 1â€“2 L4 GPU ç§Ÿç”¨ï¼‰

VM æ¶æ„ï¼šå•æœº Docker å®¹å™¨ + Python å¤šçº¿ç¨‹/å¼‚æ­¥è°ƒåº¦

Agent è§„æ¨¡ï¼šåŒæ—¶ 2â€“5 ä¸ª Claude Code æˆ– OpenAI API å®ä¾‹

ç‰¹ç‚¹ï¼šå¯ä»¥å®ç° agentic loopï¼ˆå†™ â†’ æµ‹ â†’ ä¿® â†’ å†æµ‹ï¼‰ï¼Œå¹¶å¯é€šè¿‡ Slack æˆ– Webhook æ±‡æŠ¥ç»“æœ

æˆæœ¬ï¼šçº¦ æ¯æœˆ $150 â€“ $500ï¼ˆè§† GPU å’Œ API ä½¿ç”¨é‡ï¼‰

å¯æ“ä½œæ€§ï¼šâ­ï¸â­ï¸â­ï¸â­ï¸
å¤åˆ¶éš¾åº¦ï¼šä¸­ç­‰ï¼ˆç”¨ Python + Claude API å¯å®ç°ï¼‰

â‘¢ è½»é‡æœ¬åœ°ç‰ˆï¼ˆæˆ‘ç»™ä½ çš„ mockup é¡¹ç›®ï¼‰

ç®—åŠ›æ¥æºï¼šä½ è‡ªå·±ç”µè„‘çš„ CPU ï¼ˆMacBook å®Œå…¨å¯è·‘ï¼‰

Agent æ¶æ„ï¼šå•æœºå¤šè„šæœ¬æ¨¡æ‹Ÿï¼ˆCode â†’ Test â†’ Run â†’ Repairï¼‰

Agent è§„æ¨¡ï¼š1â€“2 ä¸ªçº¿ç¨‹æ¨¡æ‹Ÿ

ç‰¹ç‚¹ï¼šç»“æ„æ­£ç¡®ï¼Œä½†ä¸è°ƒç”¨ Claude APIï¼›çº¯æ•™å­¦ä¸éªŒè¯é€»è¾‘ç”¨

æˆæœ¬ï¼š0 â‚¬

åŠŸèƒ½é™åˆ¶ï¼šä¸èƒ½æŒç»­ 24/7 æˆ–å¹¶è¡Œå¤š GPU ï¼Œä½†é€»è¾‘ç­‰ä»·

å¯æ“ä½œæ€§ï¼šâ­ï¸â­ï¸â­ï¸â­ï¸â­ï¸
å¤åˆ¶éš¾åº¦ï¼šæä½ï¼Œä»»ä½•äººå¯å¤ç°

âœ… ç»“è®º

å¦‚æœæ˜¯å…¬å¸çº§èµ„æºï¼ˆæœ‰ GPU + API é¢„ç®—ï¼‰ï¼Œå¯ä»¥ 100 % å¤åˆ¶ä»–çš„æ¶æ„ã€‚

å¦‚æœæ˜¯ä¸ªäººé¡¹ç›®ï¼Œä½ å¯ä»¥å®ç° 60â€“70 % åŠŸèƒ½ï¼ˆæ ¸å¿ƒ loopã€agent åä½œã€æµ‹è¯•æœºåˆ¶éƒ½èƒ½è·‘ï¼‰ã€‚

æœ¬åœ° mockup ç‰ˆå°±æ˜¯å…¥é—¨çº§çš„ orchestration é€»è¾‘ï¼Œæœªæ¥ä½ å¯ä»¥ä¸€æ­¥æ­¥åŠ ä¸Š Claude API ã€å¹¶è¡Œ agent å’Œ Slack æ±‡æŠ¥ï¼Œå°±èƒ½é€æ¸æ¥è¿‘ä»–çš„ç‰ˆæœ¬ã€‚

Operability and Reproducibility (Practical Analysis)

Letâ€™s look at why Federico De Ponteâ€™s system can run more than 14 Claude Code instances on 16 L4 GPUs, 24/7 â€” itâ€™s powered by enterprise-level infrastructure.
But â€” that doesnâ€™t mean you canâ€™t build a smaller, reproducible version yourself.

Below are three realistic implementation tiers ğŸ‘‡

â‘  Enterprise-Level Version (what he built)

Compute source: Google Cloud + 16 Ã— NVIDIA L4 GPUs

VM architecture: Distributed Kubernetes cluster with auto-scaling and load balancing

Agent scale: 14 â€“ 20 Claude Code instances running in parallel

Features: Fully automated, high throughput, 24/7 continuous operation

Cost: Approx. $15 000 â€“ $30 000 per month (including GPU rental and API token usage)

Operability: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸ (but only for organizations with infrastructure resources)

â‘¡ Advanced Personal Version (feasible)

Compute source: Cloud GPU services such as RunPod, Paperspace, Lambda Labs, or Google Cloud (1 â€“ 2 L4 GPUs)

VM architecture: Single machine with Docker containers + Python multi-threading/async scheduling

Agent scale: 2 â€“ 5 Claude Code or OpenAI API instances running together

Features: Implements an agentic loop (write â†’ test â†’ repair â†’ re-test) and can report via Slack or Webhook

Cost: Approx. $150 â€“ $500 per month (depending on GPU and API usage)

Operability: â­ï¸â­ï¸â­ï¸â­ï¸

Reproducibility: Medium difficulty (Python + Claude API sufficient to build)

â‘¢ Lightweight Local Version (the mockup project I gave you)

Compute source: Your own CPU (e.g., MacBook works fine)

Agent architecture: Local multi-script simulation (Code â†’ Test â†’ Run â†’ Repair)

Agent scale: 1 â€“ 2 threads simulated

Features: Correct structure, no Claude API calls â€” for educational and logic validation only

Cost: 0 â‚¬

Limitations: Cannot run 24/7 or use multi-GPU parallelism, but logical behavior is equivalent

Operability: â­ï¸â­ï¸â­ï¸â­ï¸â­ï¸

Reproducibility: Very easy â€” anyone can replicate it

âœ… Conclusion

With enterprise-level resources (GPU + API budget), you can replicate his architecture 100 %.

As a personal project, you can achieve about 60 â€“ 70 % of the functionality (core loops, agent coordination, testing mechanisms all work).

The local mockup version already contains the foundational orchestration logic â€” you can gradually add Claude API integration, parallel agents, and Slack reporting to approach his full setup.

# Agentic Orchestration System â€” Technical Overview

**He built an agentic orchestration system**  
that coordinates multiple AI coding agents (Claude Code instances) running in parallel across a GPU cluster.  
This system integrates concepts from **MLOps**, **AI Infrastructure Engineering**, and **Multi-Agent System (MAS)** design.

---

## 1ï¸âƒ£ Infrastructure Layer â€” AI Compute & Environment

At the foundation lies a robust AI infrastructure that powers continuous, large-scale computation:

- **16 Ã— NVIDIA L4 GPUs**, managed via **Google Cloud virtual machines (VMs)**.  
- Containers isolate each agentâ€™s runtime environment (e.g., Docker or Kubernetes).  
- Designed for **24/7 high-availability** and **low-latency orchestration**.

This layer ensures that multiple Claude Code instances can run safely and concurrently without resource conflicts.

---

## 2ï¸âƒ£ Orchestration Layer â€” Workflow Controller (MLOps Core)

This is the **central coordination engine**, sometimes called the *orchestrator*.  
In MLOps, it acts as the **workflow automation system**, responsible for:

- Scheduling and distributing tasks across all agents.  
- Tracking execution states and collecting feedback.  
- Triggering automatic repair or re-test cycles when failures occur.

It may be implemented through:
- Asynchronous Python controllers (`asyncio`, `FastAPI`, or message queues).  
- Workflow frameworks such as **Prefect**, **Ray**, **Airflow**, or **LangGraph**.

The orchestrator ensures synchronization between all running agents â€” enabling a continuous, self-correcting AI workflow.

---

## 3ï¸âƒ£ Agent Layer â€” Multi-Agent System (MAS)

The agent layer hosts multiple **Claude Code** instances, each assigned to a specific function.  
Together, they operate as a **multi-agent network**:

- **Code Agent** â†’ Generates core code functions.  
- **Test Agent** â†’ Produces automated unit and integration tests.  
- **Run Agent** â†’ Executes tests and reports results.  
- **Repair Agent** â†’ Fixes bugs or failed code sections.

Agents interact through the orchestratorâ€™s task routing system, ensuring that outputs from one stage become inputs for the next.

---

## 4ï¸âƒ£ Automation & Feedback Loop â€” MLOps Pipeline

The entire process follows a **closed feedback loop**, similar to a CI/CD pipeline:

1. Generate code  
2. Generate tests  
3. Run tests  
4. Repair errors  
5. Re-test until success  

Once all tests pass, the system automatically validates and stores the final code â€” no human intervention required.

This design represents an **AI-native continuous development pipeline** capable of self-evaluation and self-improvement.

---

## 5ï¸âƒ£ Observation & Reporting Layer â€” Monitoring & Collaboration

- **Slack integration** for real-time reporting of metrics, logs, and test outcomes.  
- Centralized log storage for analytics and performance tracking.  
- Human engineers can supervise progress or study system failures.

This layer bridges **human oversight** with **autonomous AI operations**.

---

## ğŸ“˜ Summary

Federicoâ€™s architecture can be described as an **AI-native agentic testing and orchestration platform**, built upon:

- **AI Infrastructure** â†’ GPU/VM computing backbone.  
- **MLOps** â†’ Automated pipeline and workflow control.  
- **Multi-Agent System (MAS)** â†’ Specialized agents collaborating via orchestration logic.

In simple terms, it is a **self-running AI software factory** â€” capable of writing, testing, and fixing code around the clock.
# ai-agent-auto-run
